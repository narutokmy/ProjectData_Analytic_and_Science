@article{2023I,
title = {Full Issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {16},
number = {10},
pages = {I-CXXII},
year = {2023},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(23)00412-6},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X23004126}
}
@article{DOGA2024880,
title = {How can quantum computing be applied in clinical trial design and optimization?},
journal = {Trends in Pharmacological Sciences},
volume = {45},
number = {10},
pages = {880-891},
year = {2024},
issn = {0165-6147},
doi = {https://doi.org/10.1016/j.tips.2024.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0165614724001676},
author = {Hakan Doga and Aritra Bose and M. Emre Sahin and Joao Bettencourt-Silva and Anh Pham and Eunyoung Kim and Alan Andress and Sudhir Saxena and Laxmi Parida and Jan Lukas Robertus and Hideaki Kawaguchi and Radwa Soliman and Daniel Blankenberg},
keywords = {quantum computing, clinical trials, healthcare, technology},
abstract = {Clinical trials are necessary for assessing the safety and efficacy of treatments. However, trial timelines are severely delayed with minimal success due to a multitude of factors, including imperfect trial site selection, cohort recruitment challenges, lack of efficacy, absence of reliable biomarkers, etc. Each of these factors possesses a unique computational challenge, such as data management, trial simulations, statistical analyses, and trial optimization. Recent advancements in quantum computing offer a promising opportunity to overcome these hurdles. In this opinion we uniquely explore the application of quantum optimization and quantum machine learning (QML) to the design and execution of clinical trials. We examine the current capabilities and limitations of quantum computing and outline its potential to streamline clinical trials.}
}
@article{2023I,
title = {Full Issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {16},
number = {6},
pages = {I-CXLIV},
year = {2023},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(23)00216-4},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X23002164}
}
@article{2019I,
title = {Full Issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {12},
number = {2},
pages = {I-CLXVI},
year = {2019},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(19)30003-8},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X19300038}
}
@article{ARGIRIS2023120237,
title = {Simple topological task-based functional connectivity features predict longitudinal behavioral change of fluid reasoning in the RANN cohort},
journal = {NeuroImage},
volume = {277},
pages = {120237},
year = {2023},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2023.120237},
url = {https://www.sciencedirect.com/science/article/pii/S1053811923003889},
author = {Georgette Argiris and Yaakov Stern and Seonjoo Lee and Hyunnam Ryu and Christian Habeck},
keywords = {Cognitive aging, RANN, TDA, System segregation, Task-based functional connectivity, Longitudinal},
abstract = {Recent attention has been given to topological data analysis (TDA), and more specifically persistent homology (PH), to identify the underlying shape of brain network connectivity beyond simple edge pairings by computing connective components across different connectivity thresholds (see Sizemore et al., 2019). In the present study, we applied PH to task-based functional connectivity, computing 0-dimension Betti (B0) curves and calculating the area under these curves (AUC); AUC indicates how quickly a single connected component is formed across correlation filtration thresholds, with lower values interpreted as potentially analogous to lower whole-brain system segregation (e.g., Gracia-Tabuenca et al., 2020). One hundred sixty-three participants from the Reference Ability Neural Network (RANN) longitudinal lifespan cohort (age 20–80 years) were tested in-scanner at baseline and five-year follow-up on a battery of tests comprising four domains of cognition (i.e., Stern et al., 2014). We tested for 1.) age-related change in the AUC of the B0 curve over time, 2.) the predictive utility of AUC in accounting for longitudinal change in behavioral performance and 3.) compared system segregation to the PH approach. Results demonstrated longitudinal age-related decreases in AUC for Fluid Reasoning, with these decreases predicting longitudinal declines in cognition, even after controlling for demographic and brain integrity factors; moreover, change in AUC partially mediated the effect of age on change in cognitive performance. System segregation also significantly decreased with age in three of the four cognitive domains but did not predict change in cognition. These results argue for greater application of TDA to the study of aging.}
}
@article{2020I,
title = {Full Issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {13},
number = {8},
pages = {I-CCXXIV},
year = {2020},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(20)30581-7},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X20305817}
}
@article{BATTISTON20201,
title = {Networks beyond pairwise interactions: Structure and dynamics},
journal = {Physics Reports},
volume = {874},
pages = {1-92},
year = {2020},
note = {Networks beyond pairwise interactions: Structure and dynamics},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2020.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0370157320302489},
author = {Federico Battiston and Giulia Cencetti and Iacopo Iacopini and Vito Latora and Maxime Lucas and Alice Patania and Jean-Gabriel Young and Giovanni Petri},
abstract = {The complexity of many biological, social and technological systems stems from the richness of the interactions among their units. Over the past decades, a variety of complex systems has been successfully described as networks whose interacting pairs of nodes are connected by links. Yet, from human communications to chemical reactions and ecological systems, interactions can often occur in groups of three or more nodes and cannot be described simply in terms of dyads. Until recently little attention has been devoted to the higher-order architecture of real complex systems. However, a mounting body of evidence is showing that taking the higher-order structure of these systems into account can enhance our modeling capacities and help us understand and predict their dynamical behavior. Here we present a complete overview of the emerging field of networks beyond pairwise interactions. We discuss how to represent higher-order interactions and introduce the different frameworks used to describe higher-order systems, highlighting the links between the existing concepts and representations. We review the measures designed to characterize the structure of these systems and the models proposed to generate synthetic structures, such as random and growing bipartite graphs, hypergraphs and simplicial complexes. We introduce the rapidly growing research on higher-order dynamical systems and dynamical topology, discussing the relations between higher-order interactions and collective behavior. We focus in particular on new emergent phenomena characterizing dynamical processes, such as diffusion, synchronization, spreading, social dynamics and games, when extended beyond pairwise interactions. We conclude with a summary of empirical applications, and an outlook on current modeling and conceptual frontiers.}
}
@article{2021I,
title = {Full Issue},
journal = {JACC: Cardiovascular Imaging},
volume = {14},
number = {10},
pages = {I-CLXXV},
year = {2021},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(21)00676-8},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X21006768}
}
@article{KALANTARI20182,
title = {Computational intelligence approaches for classification of medical data: State-of-the-art, future challenges and research directions},
journal = {Neurocomputing},
volume = {276},
pages = {2-22},
year = {2018},
note = {Machine Learning and Data Mining Techniques for Medical Complex Data Analysis},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.126},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217315436},
author = {Ali Kalantari and Amirrudin Kamsin and Shahaboddin Shamshirband and Abdullah Gani and Hamid Alinejad-Rokny and Anthony T. Chronopoulos},
keywords = {Computational intelligence, Medical application, Big data, Detection, Ensemble algorithm},
abstract = {The explosive growth of data in volume, velocity and diversity that are produced by medical applications has contributed to abundance of big data. Current solutions for efficient data storage and management cannot fulfill the needs of heterogeneous data. Therefore, by applying computational intelligence (CI) approaches in medical data helps get better management, faster performance and higher level of accuracy in detection. This paper aims to investigate the state-of-the-art of computational intelligence approaches in medical data and to categorize the existing CI techniques, used in medical fields, as single and hybrid. In addition, the techniques and methodologies, their limitations and performances are presented in this study. The limitations are addressed as challenges to obtain a set of requirements for Computational Intelligence Medical Data (CIMD) in establishing an efficient CIMD architectural design. The results show that on the one hand Support Vector Machine (SVM) and Artificial Immune Recognition System (AIRS) as a single based computational intelligence approach were the best methods in medical applications. On the other hand, the hybridization of SVM with other methods such as SVM-Genetic Algorithm (SVM-GA), SVM-Artificial Immune System (SVM-AIS), SVM-AIRS and fuzzy support vector machine (FSVM) had great performances achieving better results in terms of accuracy, sensitivity and specificity.}
}
@article{IBANEZMARCELO2019437,
title = {Topology highlights mesoscopic functional equivalence between imagery and perception: The case of hypnotizability},
journal = {NeuroImage},
volume = {200},
pages = {437-449},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2019.06.044},
url = {https://www.sciencedirect.com/science/article/pii/S1053811919305415},
author = {Esther Ibáñez-Marcelo and Lisa Campioni and Angkoon Phinyomark and Giovanni Petri and Enrica L. Santarcangelo},
keywords = {Hypnotizability, Imagery, Persistent homology, EEG},
abstract = {The functional equivalence (FE) between imagery and perception or motion has been proposed on the basis of neuroimaging evidence of large spatially overlapping activations between real and imagined sensori-motor conditions. However, similar local activation patterns do not imply the same mesoscopic integration of brain regions, which can be described by tools from Topological Data Analysis (TDA). On the basis of behavioral findings, stronger FE has been hypothesized in the individuals with high scores of hypnotizability scores (highs) with respect to low hypnotizable participants (lows) who differ between each other in the proneness to modify memory, perception and behavior according to specific imaginative suggestions. Here we present the first EEG evidence of stronger FE in highs. In fact, persistent homology shows that the highs EEG topological asset during real and imagined sensory conditions is significantly more similar than the lows. As a corollary finding, persistent homology shows lower restructuring of the EEG asset in highs than in lows during both sensory and imagery tasks with respect to basal conditions. Present findings support the view that greater embodiment of mental images may be responsible for the highs greater proneness to respond to sensori-motor suggestions and to report involuntariness in action. In addition, findings indicate hypnotizability-related sensory and cognitive information processing and suggest that the psycho-physiological trait of hypnotizability may modulate more than one aspect of the everyday life.}
}
@incollection{2023237,
title = {Index},
editor = {Steven G. Krantz and Arni S.R. {Srinivasa Rao} and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {49},
pages = {237-242},
year = {2023},
booktitle = {Artificial Intelligence},
issn = {0169-7161},
doi = {https://doi.org/10.1016/S0169-7161(23)00046-9},
url = {https://www.sciencedirect.com/science/article/pii/S0169716123000469}
}
@article{2021I,
title = {Full Issue},
journal = {JACC: Cardiovascular Imaging},
volume = {14},
number = {7},
pages = {I-CC},
year = {2021},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(21)00483-6},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X21004836}
}
@article{2024101309,
title = {Full Issue PDF},
journal = {JACC: Advances},
volume = {3},
number = {9, Part 2},
pages = {101309},
year = {2024},
note = {AI in Cardiology: Improving Outcomes for All Focus Issue},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2024.101309},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X24005878}
}
@article{KAGIYAMA2020102726,
title = {A low-cost texture-based pipeline for predicting myocardial tissue remodeling and fibrosis using cardiac ultrasound},
journal = {EBioMedicine},
volume = {54},
pages = {102726},
year = {2020},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2020.102726},
url = {https://www.sciencedirect.com/science/article/pii/S2352396420301018},
author = {Nobuyuki Kagiyama and Sirish Shrestha and Jung Sun Cho and Muhammad Khalil and Yashbir Singh and Abhiram Challa and Grace Casaclang-Verzosa and Partho P. Sengupta},
keywords = {Echocardiography, Machine learning, Radiomics, Clustering, Tissue characterization},
abstract = {Background
Maturation of ultrasound myocardial tissue characterization may have far-reaching implications as a widely available alternative to cardiac magnetic resonance (CMR) for risk stratification in left ventricular (LV) remodeling.
Methods
We extracted 328 texture-based features of myocardium from still ultrasound images. After we explored the phenotypes of myocardial textures using unsupervised similarity networks, global LV remodeling parameters were predicted using supervised machine learning models. Separately, we also developed supervised models for predicting the presence of myocardial fibrosis using another cohort who underwent cardiac magnetic resonance (CMR). For the prediction, patients were divided into a training and test set (80:20).
Findings
Texture-based tissue feature extraction was feasible in 97% of total 534 patients. Interpatient similarity analysis delineated two patient groups based on the texture features: one group had more advanced LV remodeling parameters compared to the other group. Furthermore, this group was associated with a higher incidence of cardiac deaths (p = 0.001) and major adverse cardiac events (p < 0.001). The supervised models predicted reduced LV ejection fraction (<50%) and global longitudinal strain (<16%) with area under the receiver-operator-characteristics curves (ROC AUC) of 0.83 and 0.87 in the hold-out test set, respectively. Furthermore, the presence of myocardial fibrosis was predicted from only ultrasound myocardial texture with an ROC AUC of 0.84 (sensitivity 86.4% and specificity 83.3%) in the test set.
Interpretation
Ultrasound texture-based myocardial tissue characterization identified phenotypic features of LV remodeling from still ultrasound images. Further clinical validation may address critical barriers in the adoption of ultrasound techniques for myocardial tissue characterization.
Funding
None.}
}
@article{2019B1,
title = {2019 ASE 30th Annual Scientific Sessions},
journal = {Journal of the American Society of Echocardiography},
volume = {32},
number = {6},
pages = {B1-B137},
year = {2019},
note = {American Society of Echocardiography 30th Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/j.echo.2019.04.414},
url = {https://www.sciencedirect.com/science/article/pii/S0894731719306157}
}
@article{EHLERS2024104115,
title = {An introduction to and survey of biological network visualization},
journal = {Computers & Graphics},
pages = {104115},
year = {2024},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2024.104115},
url = {https://www.sciencedirect.com/science/article/pii/S0097849324002504},
author = {Henry Ehlers and Nicolas Brich and Michael Krone and Martin Nöllenburg and Jiacheng Yu and Hiroaki Natsukawa and Xiaoru Yuan and Hsiang-Yun Wu},
keywords = {Network visualization, Biological networks, State-of-the-art-report, Visualization pipeline, Sensemaking loop, Visual analytics, Network analysis},
abstract = {Biological networks describe complex relationships in biological systems, which represent biological entities as vertices and their underlying connectivity as edges. Ideally, for a complete analysis of such systems, domain experts need to visually integrate multiple sources of heterogeneous data, and visually, as well as numerically, probe said data in order to explore or validate (mechanistic) hypotheses. Such visual analyses require the coming together of biological domain experts, bioinformaticians, as well as network scientists to create useful visualization tools. Owing to the underlying graph data becoming ever larger and more complex, the visual representation of such biological networks has become challenging in its own right. This introduction and survey aims to describe the current state of biological network visualization in order to identify scientific gaps for visualization experts, network scientists, bioinformaticians, and domain experts, such as biologists, or biochemists, alike. Specifically, we revisit the classic visualization pipeline, upon which we base this paper’s taxonomy and structure, which in turn forms the basis of our literature classification. This pipeline describes the process of visualizing data, starting with the raw data itself, through the construction of data tables, to the actual creation of visual structures and views, as a function of task-driven user interaction. Literature was systematically surveyed using API-driven querying where possible, and the collected papers were manually read and categorized based on the identified sub-components of this visualization pipeline’s individual steps. From this survey, we highlight a number of exemplary visualization tools from multiple biological sub-domains in order to explore how they adapt these discussed techniques and why. Additionally, this taxonomic classification of the collected set of papers allows us to identify existing gaps in biological network visualization practices. We finally conclude this report with a list of open challenges and potential research directions. Examples of such gaps include (i) the overabundance of visualization tools using schematic or straight-line node-link diagrams, despite the availability of powerful alternatives, or (ii) the lack of visualization tools that also integrate more advanced network analysis techniques beyond basic graph descriptive statistics.}
}
@article{TALESHJAFADIDEH2022106202,
title = {Topological analysis of brain dynamics in autism based on graph and persistent homology},
journal = {Computers in Biology and Medicine},
volume = {150},
pages = {106202},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106202},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522009106},
author = {Alireza {Talesh Jafadideh} and Babak {Mohammadzadeh Asl}},
keywords = {Autism spectrum disorder, Typical control, Diffusion tensor imaging, Graph, Persistent homology, Resting-state fMRI, Dynamic functional connectivity},
abstract = {Autism spectrum disorder (ASD) is a heterogeneous disorder with a rapidly growing prevalence. In recent years, the dynamic functional connectivity (DFC) technique has been used to reveal the transient connectivity behavior of ASDs' brains by clustering connectivity matrices in different states. However, the states of DFC have not been yet studied from a topological point of view. In this paper, this study was performed using global metrics of the graph and persistent homology (PH) and resting-state functional magnetic resonance imaging (fMRI) data. The PH has been recently developed in topological data analysis and deals with persistent structures of data. The structural connectivity (SC) and static FC (SFC) were also studied to know which one of the SC, SFC, and DFC could provide more discriminative topological features when comparing ASDs with typical controls (TCs). Significant discriminative features were only found in states of DFC. Moreover, the best classification performance was offered by persistent homology-based metrics and in two out of four states. In these two states, some networks of ASDs compared to TCs were more segregated and isolated (showing the disruption of network integration in ASDs). The results of this study demonstrated that topological analysis of DFC states could offer discriminative features which were not discriminative in SFC and SC. Also, PH metrics can provide a promising perspective for studying ASD and finding candidate biomarkers.}
}
@article{2022I,
title = {Full issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {15},
number = {6},
pages = {I-CCXVII},
year = {2022},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(22)00300-X},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X2200300X}
}
@article{MONTANS2019845,
title = {Data-driven modeling and learning in science and engineering},
journal = {Comptes Rendus Mécanique},
volume = {347},
number = {11},
pages = {845-855},
year = {2019},
note = {Data-Based Engineering Science and Technology},
issn = {1631-0721},
doi = {https://doi.org/10.1016/j.crme.2019.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S1631072119301809},
author = {Francisco J. Montáns and Francisco Chinesta and Rafael Gómez-Bombarelli and J. Nathan Kutz},
keywords = {Data-driven science, Data-driven modeling, Artificial intelligence, Machine learning, Data-science, Big data},
abstract = {In the past, data in which science and engineering is based, was scarce and frequently obtained by experiments proposed to verify a given hypothesis. Each experiment was able to yield only very limited data. Today, data is abundant and abundantly collected in each single experiment at a very small cost. Data-driven modeling and scientific discovery is a change of paradigm on how many problems, both in science and engineering, are addressed. Some scientific fields have been using artificial intelligence for some time due to the inherent difficulty in obtaining laws and equations to describe some phenomena. However, today data-driven approaches are also flooding fields like mechanics and materials science, where the traditional approach seemed to be highly satisfactory. In this paper we review the application of data-driven modeling and model learning procedures to different fields in science and engineering.}
}
@article{2018B1,
title = {2018 ASE 29th Annual Scientific Sessions},
journal = {Journal of the American Society of Echocardiography},
volume = {31},
number = {6},
pages = {B1-B142},
year = {2018},
note = {American Society of Echocardiography 28th Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/j.echo.2018.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0894731718302049}
}
@incollection{2025421,
title = {Subject Index},
editor = {Seifedine Kadry and Shubham Mahajan},
booktitle = {Data Science in the Medical Field},
publisher = {Academic Press},
pages = {421-435},
year = {2025},
isbn = {978-0-443-24028-7},
doi = {https://doi.org/10.1016/B978-0-443-24028-7.00037-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443240287000374}
}
@article{MAUDSLEY2018961,
title = {Intelligent and effective informatic deconvolution of “Big Data” and its future impact on the quantitative nature of neurodegenerative disease therapy},
journal = {Alzheimer's & Dementia},
volume = {14},
number = {7},
pages = {961-975},
year = {2018},
issn = {1552-5260},
doi = {https://doi.org/10.1016/j.jalz.2018.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S1552526018300402},
author = {Stuart Maudsley and Viswanath Devanarayan and Bronwen Martin and Hugo Geerts},
keywords = {Big data, Informatics, High-dimensionality, Alzheimer's disease, Aging, Molecular signature, Transcriptomics, Metabolomics, Proteomics, Genomics},
abstract = {Biomedical data sets are becoming increasingly larger and a plethora of high-dimensionality data sets (“Big Data”) are now freely accessible for neurodegenerative diseases, such as Alzheimer's disease. It is thus important that new informatic analysis platforms are developed that allow the organization and interrogation of Big Data resources into a rational and actionable mechanism for advanced therapeutic development. This will entail the generation of systems and tools that allow the cross-platform correlation between data sets of distinct types, for example, transcriptomic, proteomic, and metabolomic. Here, we provide a comprehensive overview of the latest strategies, including latent semantic analytics, topological data investigation, and deep learning techniques that will drive the future development of diagnostic and therapeutic applications for Alzheimer's disease. We contend that diverse informatic “Big Data” platforms should be synergistically designed with more advanced chemical/drug and cellular/tissue-based phenotypic analytical predictive models to assist in either de novo drug design or effective drug repurposing.}
}
@article{WILCOX2017194,
title = {Generating level-dependent models of cervical and thoracic spinal cord injury: Exploring the interplay of neuroanatomy, physiology, and function},
journal = {Neurobiology of Disease},
volume = {105},
pages = {194-212},
year = {2017},
issn = {0969-9961},
doi = {https://doi.org/10.1016/j.nbd.2017.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0969996117301213},
author = {Jared T. Wilcox and Kajana Satkunendrarajah and Yasmin Nasirzadeh and Alex M. Laliberte and Alyssa Lip and David W. Cadotte and Warren D. Foltz and Michael G. Fehlings},
keywords = {Spinal Cord Injury, Cervical, Thoracic, Clip compression, Magnetic resonance imaging, Forelimb, Gait analysis, Motor neuron survival, Principal component analysis, Discriminant function analysis},
abstract = {The majority of spinal cord injuries (SCI) occur at the cervical level, which results in significant impairment. Neurologic level and severity of injury are primary endpoints in clinical trials; however, how level-specific damages relate to behavioural performance in cervical injury is incompletely understood. We hypothesized that ascending level of injury leads to worsening forelimb performance, and correlates with loss of neural tissue and muscle-specific neuron pools. A direct comparison of multiple models was made with injury realized at the C5, C6, C7 and T7 vertebral levels using clip compression with sham-operated controls. Animals were assessed for 10weeks post-injury with numerous (40) outcome measures, including: classic behavioural tests, CatWalk, non-invasive MRI, electrophysiology, histologic lesion morphometry, neuron counts, and motor compartment quantification, and multivariate statistics on the total dataset. Histologic staining and T1-weighted MR imaging revealed similar structural changes and distinct tissue loss with cystic cavitation across all injuries. Forelimb tests, including grip strength, F-WARP motor scale, Inclined Plane, and forelimb ladder walk, exhibited stratification between all groups and marked impairment with C5 and C6 injuries. Classic hindlimb tests including BBB, hindlimb ladder walk, bladder recovery, and mortality were not different between cervical and thoracic injuries. CatWalk multivariate gait analysis showed reciprocal and progressive changes forelimb and hindlimb function with ascending level of injury. Electrophysiology revealed poor forelimb axonal conduction in cervical C5 and C6 groups alone. The cervical enlargement (C5-T2) showed progressive ventral horn atrophy and loss of specific motor neuron populations with ascending injury. Multivariate statistics revealed a robust dataset, rank-order contribution of outcomes, and allowed prediction of injury level with single-level discrimination using forelimb performance and neuron counts. Level-dependent models were generated using clip-compression SCI, with marked and reliable differences in forelimb performance and specific neuron pool loss.}
}
@article{WENCHENG2023e18517,
title = {Visual number sense for real-world scenes shared by deep neural networks and humans},
journal = {Heliyon},
volume = {9},
number = {8},
pages = {e18517},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e18517},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023057250},
author = {Wu Wencheng and Yingxi Ge and Zhentao Zuo and Lin Chen and Xu Qin and Liu Zuxiang},
keywords = {Number sense, Deep neural network, Real-world scene, Group coding, Embedded representation},
abstract = {Recently, visual number sense has been identified from deep neural networks (DNNs). However, whether DNNs have the same capacity for real-world scenes, rather than the simple geometric figures that are often tested, is unclear. In this study, we explore the number perception of scenes using AlexNet and find that numerosity can be represented by the pattern of group activation of the category layer units. The global activation of these units increases with the number of objects in the scene, and the variations in their activation decrease accordingly. By decoding the numerosity from this pattern, we reveal that the embedding coefficient of a scene determines the likelihood of potential objects to contribute to numerical perception. This was demonstrated by the more optimized performance for pictures with relatively high embedding coefficients in both DNNs and humans. This study for the first time shows that a distinct feature in visual environments, revealed by DNNs, can modulate human perception, supported by a group-coding mechanism.}
}
@article{DEMARCHI2022100050,
title = {Variably Scaled Persistence Kernels (VSPKs) for persistent homology applications},
journal = {Journal of Computational Mathematics and Data Science},
volume = {4},
pages = {100050},
year = {2022},
issn = {2772-4158},
doi = {https://doi.org/10.1016/j.jcmds.2022.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2772415822000153},
author = {Stefano {De Marchi} and Federico Lot and Francesco Marchetti and Davide Poggiali},
keywords = {Kernel-based learning, Variably scaled persistence kernel, Persistence diagrams, Persistent homology},
abstract = {In recent years, various kernels have been proposed in the context of persistent homology to deal with persistence diagrams in supervised learning approaches. In this paper, we consider the idea of variably scaled kernels, for approximating functions and data, and we interpret it in the framework of persistent homology. We call them Variably Scaled Persistence Kernels (VSPKs). These new kernels are then tested in different classification experiments. The obtained results show that they can improve the performance and the efficiency of existing standard kernels.}
}
@incollection{SEETHARAM2021383,
title = {Chapter 19 - Artificial intelligence in cardiovascular imaging},
editor = {Lei Xing and Maryellen L. Giger and James K. Min},
booktitle = {Artificial Intelligence in Medicine},
publisher = {Academic Press},
pages = {383-393},
year = {2021},
isbn = {978-0-12-821259-2},
doi = {https://doi.org/10.1016/B978-0-12-821259-2.00019-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128212592000193},
author = {Karthik Seetharam and James K. Min},
keywords = {Artificial intelligence, machine learning, cardiovascular disease, cardiovascular imaging, echocardiography},
abstract = {The emergence of artificial intelligence (AI) has sparked tremendous interest in the academic community, commercial industries, and society with wide-ranging applications from self-driving cars to automated voice recognition. With the explosive progress of AI, the field of cardiovascular imaging is no exception. Cardiovascular disease is one of the leading causes of mortality and morbidity, various diagnostic modalities play a paramount role in patient evaluation. As data originating form imaging and health care is becoming increasing complex for conventional statistics, this places us at a delicate crossroads. Machine learning (ML), a subset of AI, has shown significant promise and will help cardiovascular imaging transcend to new heights. In this review, we herein describe the role of ML to date in various imaging modalities for in cardiovascular disease.}
}
@article{MARZOLA2024105972,
title = {An enhanced statistical shape model for automatic feature segmentation of human vertebrae},
journal = {Biomedical Signal Processing and Control},
volume = {91},
pages = {105972},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.105972},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424000302},
author = {Antonio Marzola and Luca {Di Angelo} and Paolo {Di Stefano} and Yary Volpe},
keywords = {Computer methods for vertebra analysis, 3D medical image analysis, Shape segmentation, Statistical Shape Analysis, Bio-informatics},
abstract = {Background & objective
Human vertebrae are analysed and measured for various purposes, including to study anatomy, to diagnose illness, and to evaluate therapies. Achieving an accurate morphological and dimensional characterisation of three-dimensional (3D) vertebrae relies on the precise recognition of their features. Traditionally, these features, lacking defined edges, have been identified manually through a time-consuming, poorly repeatable, and poorly reproducible process. To the authors’ knowledge, there is only one method published in the literature able to automatically recognise all the most important vertebral features: the algorithmic feature recognition method (AFRM). It requires a high-density point cloud as input, the presence of all morphological features, even if incomplete, and incurs high computational costs. This research aims to propose an improved version of the AFRM to overcome its limitations.
Methods
The proposed approach combines the robustness of AFRM to provide the semantic segmentation of a 3D healthy human vertebra with the ability of the enhanced statistical shape model (eSSM) to transfer information among different models. Specifically, AFRM provides the semantic segmentation of the mean shape of the eSSM, while the latter transfers this information to target shapes.
Results
The eSSM was developed using 20 training samples of healthy adult male L2 vertebrae. The test samples included five healthy vertebrae and four vertebras with large missing parts. None of the test shapes were included in the training set. The novel approach could accurately recognise morphological features without the constraints that affect the AFRM.
Conclusion
The proposed method guarantees reliable and automated segmentation through AFRM, exploiting the eSSM’s ability to provide results even when dealing with sparsely populated or partially incomplete target models, significantly reducing the computational load.}
}
@article{2021I,
title = {Full Issue},
journal = {JACC: Cardiovascular Imaging},
volume = {14},
number = {9},
pages = {I-CXCIX},
year = {2021},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(21)00619-7},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X21006197}
}
@incollection{2024509,
title = {Index},
editor = {Pawan Kumar Raghav and Rajesh Kumar and Anjali Lathwal and Navneet Sharma},
booktitle = {Computational Biology for Stem Cell Research},
publisher = {Academic Press},
pages = {509-520},
year = {2024},
isbn = {978-0-443-13222-3},
doi = {https://doi.org/10.1016/B978-0-443-13222-3.20002-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132223200026}
}
@article{RUEQUERALT2021118611,
title = {The connectome spectrum as a canonical basis for a sparse representation of fast brain activity},
journal = {NeuroImage},
volume = {244},
pages = {118611},
year = {2021},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2021.118611},
url = {https://www.sciencedirect.com/science/article/pii/S1053811921008843},
author = {Joan Rué-Queralt and Katharina Glomb and David Pascucci and Sébastien Tourbier and Margherita Carboni and Serge Vulliémoz and Gijs Plomp and Patric Hagmann},
abstract = {The functional organization of neural processes is constrained by the brain's intrinsic structural connectivity, i.e., the connectome. Here, we explore how structural connectivity can improve the representation of brain activity signals and their dynamics. Using a multi-modal imaging dataset (electroencephalography, structural MRI, and diffusion MRI), we represent electrical brain activity at the cortical surface as a time-varying composition of harmonic modes of structural connectivity. These harmonic modes are known as connectome harmonics. Here we describe brain activity signal as a time-varying combination of connectome harmonics. We term this description as the connectome spectrum of the signal. We found that: first, the brain activity signal is represented more compactly by the connectome spectrum than by the traditional area-based representation; second, the connectome spectrum characterizes fast brain dynamics in terms of signal broadcasting profile, revealing different temporal regimes of integration and segregation that are consistent across participants. And last, the connectome spectrum characterizes fast brain dynamics with fewer degrees of freedom than area-based signal representations. Specifically, we show that a smaller number of dimensions capture the differences between low-level and high-level visual processing in the connectome spectrum. Also, we demonstrate that connectome harmonics capture more sensitively the topological properties of brain activity. In summary, this work provides statistical, functional, and topological evidence indicating that the description of brain activity in terms of structural connectivity fosters a more comprehensive understanding of large-scale dynamic neural functioning.}
}
@article{SAGGAR2022119686,
title = {Neural resources shift under Methylphenidate: A computational approach to examine anxiety-cognition interplay},
journal = {NeuroImage},
volume = {264},
pages = {119686},
year = {2022},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2022.119686},
url = {https://www.sciencedirect.com/science/article/pii/S1053811922008072},
author = {Manish Saggar and Jennifer Bruno and Claudie Gaillard and Leonardo Claudino and Monique Ernst},
abstract = {The reciprocal interplay between anxiety and cognition is well documented. Anxiety negatively impacts cognition, while cognitive engagement can down-regulate anxiety. The brain mechanisms and dynamics underlying such interplay are not fully understood. To study this question, we experimentally and orthogonally manipulated anxiety (using a threat of shock paradigm) and cognition (using methylphenidate; MPH). The effects of these manipulations on the brain and behavior were evaluated in 50 healthy participants (25 MPH, 25 placebo), using an n-back working memory fMRI task (with low and high load conditions). Behaviorally, improved response accuracy was observed as a main effect of the drug across all conditions. We employed two approaches to understand the neural mechanisms underlying MPH-based cognitive enhancement in safe and threat conditions. First, we performed a hypothesis-driven computational analysis using a mathematical framework to examine how MPH putatively affects cognitive enhancement in the face of induced anxiety across two levels of cognitive load. Second, we performed an exploratory data analysis using Topological Data Analysis (TDA)-based Mapper to examine changes in spatiotemporal brain activity across the entire cortex. Both approaches provided converging evidence that MPH facilitated greater differential engagement of neural resources (brain activity) across low and high working memory load conditions. Furthermore, load-based differential management of neural resources reflects enhanced efficiency that is most powerful during higher load and induced anxiety conditions. Overall, our results provide novel insights regarding brain mechanisms that facilitate cognitive enhancement under MPH and, in future research, may be used to help mitigate anxiety-related cognitive underperformance.}
}
@article{GUO2020150,
title = {Learning to upgrade internet information security and protection strategy in big data era},
journal = {Computer Communications},
volume = {160},
pages = {150-157},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.05.043},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420301559},
author = {Junjun Guo and Le Wang},
keywords = {Big data, Network information security, Improved KPCA algorithm, Intrusion detection, KDDCUP99 data set},
abstract = {Nowadays, we are in a typical information age, and network and information security systems are facing severe challenges. However, there is currently no suitable method for the detailed analysis and protection of Internet information security. In order to analyze Internet security information more accurately, we proposed an improved KPCA (Kernel Principle Component Analysis) algorithm within the context of the big data era and in view of the shortcomings and disadvantages of the KPCA feature extraction algorithm. The proposed algorithm not only retains its performance ability, but also improves the subsequent classification ability. This paper uses the KDDCUP99 security audit data set to simulate network intrusions, and the data set used network information data resources within a total of 9 weeks. The training data set contains a total of 7 weeks of data information, and the other 2 weeks of data information are used as a validation data set. The training data set contains a total of 5 million records of network security information, while the verification data set contains 2 million records. The experimental results show that for the network intrusion classification test, the improved algorithm is more efficient, convenient, and faster than the traditional KPCA one. Furthermore, the simulation results also show that the proposed algorithm has achieved a very high degree of accuracy and improvement in terms of “accuracy rate,” “false alarm rate,” and “missing alarm rate.”}
}
@article{XIE2021118531,
title = {Spontaneous and deliberate modes of creativity: Multitask eigen-connectivity analysis captures latent cognitive modes during creative thinking},
journal = {NeuroImage},
volume = {243},
pages = {118531},
year = {2021},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2021.118531},
url = {https://www.sciencedirect.com/science/article/pii/S1053811921008041},
author = {Hua Xie and Roger E. Beaty and Sahar Jahanikia and Caleb Geniesse and Neeraj S. Sonalkar and Manish Saggar},
keywords = {Creativity, Deliberate/spontaneous thinking, Dual-process model, Multitask fMRI, Whole-brain functional connectivity, Eigen-connectivity},
abstract = {Despite substantial progress in the quest of demystifying the brain basis of creativity, several questions remain open. One such issue concerns the relationship between two latent cognitive modes during creative thinking, i.e., deliberate goal-directed cognition and spontaneous thought generation. Although an interplay between deliberate and spontaneous thinking is often implicated in the creativity literature (e.g., dual-process models), a bottom-up data-driven validation of the cognitive processes associated with creative thinking is still lacking. Here, we attempted to capture the latent modes of creative thinking by utilizing a data-driven approach on a novel continuous multitask paradigm (CMP) that widely sampled a hypothetical two-dimensional cognitive plane of deliberate and spontaneous thinking in a single fMRI session. The CMP consisted of eight task blocks ranging from undirected mind wandering to goal-directed working memory task, while also included two widely-used creativity tasks, i.e., alternate uses task (AUT) and remote association task (RAT). Using eigen-connectivity (EC) analysis on the multitask whole-brain functional connectivity (FC) patterns, we embedded the multitask FCs into a low-dimensional latent space. The first two latent components, as revealed by the EC analysis, broadly mapped onto the two cognitive modes of deliberate and spontaneous thinking, respectively. Further, in this low-dimensional space, both creativity tasks were located in the upper right corner of high deliberate and spontaneous thinking (creative cognitive space). Neuroanatomically, the creative cognitive space was represented by not only increased intra-network connectivity within executive control and default mode network, but also by higher coupling between the two canonical brain networks. Further, individual differences reflected in the low-dimensional connectivity embeddings were related to differences in deliberate and spontaneous thinking abilities. Altogether, using a continuous multitask paradigm and a data-driven approach, we provide initial empirical evidence for the contribution of both deliberate and spontaneous modes of cognition during creative thinking.}
}
@article{HASSAINE2020111325,
title = {Untangling the complexity of multimorbidity with machine learning},
journal = {Mechanisms of Ageing and Development},
volume = {190},
pages = {111325},
year = {2020},
issn = {0047-6374},
doi = {https://doi.org/10.1016/j.mad.2020.111325},
url = {https://www.sciencedirect.com/science/article/pii/S0047637420301214},
author = {Abdelaali Hassaine and Gholamreza Salimi-Khorshidi and Dexter Canoy and Kazem Rahimi},
keywords = {Machine learning, Deep learning, Multimorbidity, Electronic health records, Phenotyping},
abstract = {The prevalence of multimorbidity has been increasing in recent years, posing a major burden for health care delivery and service. Understanding its determinants and impact is proving to be a challenge yet it offers new opportunities for research to go beyond the study of diseases in isolation. In this paper, we review how the field of machine learning provides many tools for addressing research challenges in multimorbidity. We highlight recent advances in promising methods such as matrix factorisation, deep learning, and topological data analysis and how these can take multimorbidity research beyond cross-sectional, expert-driven or confirmatory approaches to gain a better understanding of evolving patterns of multimorbidity. We discuss the challenges and opportunities of machine learning to identify likely causal links between previously poorly understood disease associations while giving an estimate of the uncertainty on such associations. We finally summarise some of the challenges for wider clinical adoption of machine learning research tools and propose some solutions.}
}
@article{2020I,
title = {Full Issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {13},
number = {5},
pages = {I-CXCVI},
year = {2020},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(20)30301-6},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X20303016}
}
@article{SKAF2022104082,
title = {Topological data analysis in biomedicine: A review},
journal = {Journal of Biomedical Informatics},
volume = {130},
pages = {104082},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104082},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422000983},
author = {Yara Skaf and Reinhard Laubenbacher},
keywords = {Biomedical informatics, Personalized medicine, Big data analytics, Topological data analysis, TDA, Applied topology, Mapper, Persistent homology, Machine learning},
abstract = {Significant technological advances made in recent years have shepherded a dramatic increase in utilization of digital technologies for biomedicine– everything from the widespread use of electronic health records to improved medical imaging capabilities and the rising ubiquity of genomic sequencing contribute to a “digitization” of biomedical research and clinical care. With this shift toward computerized tools comes a dramatic increase in the amount of available data, and current tools for data analysis capable of extracting meaningful knowledge from this wealth of information have yet to catch up. This article seeks to provide an overview of emerging mathematical methods with the potential to improve the abilities of clinicians and researchers to analyze biomedical data, but may be hindered from doing so by a lack of conceptual accessibility and awareness in the life sciences research community. In particular, we focus on topological data analysis (TDA), a set of methods grounded in the mathematical field of algebraic topology that seeks to describe and harness features related to the “shape” of data. We aim to make such techniques more approachable to non-mathematicians by providing a conceptual discussion of their theoretical foundations followed by a survey of their published applications to scientific research. Finally, we discuss the limitations of these methods and suggest potential avenues for future work integrating mathematical tools into clinical care and biomedical informatics.}
}
@article{CAPUTI2021118245,
title = {Promises and pitfalls of topological data analysis for brain connectivity analysis},
journal = {NeuroImage},
volume = {238},
pages = {118245},
year = {2021},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2021.118245},
url = {https://www.sciencedirect.com/science/article/pii/S105381192100522X},
author = {Luigi Caputi and Anna Pidnebesna and Jaroslav Hlinka},
keywords = {Persistent homology, Connectivity, fMRI, Electrophysiology, Epilepsy, Schizophrenia},
abstract = {Developing sensitive and reliable methods to distinguish normal and abnormal brain states is a key neuroscientific challenge. Topological Data Analysis, despite its relative novelty, already generated many promising applications, including in neuroscience. We conjecture its prominent tool of persistent homology may benefit from going beyond analysing structural and functional connectivity to effective connectivity graphs capturing the direct causal interactions or information flows. Therefore, we assess the potential of persistent homology to directed brain network analysis by testing its discriminatory power in two distinctive examples of disease-related brain connectivity alterations: epilepsy and schizophrenia. We estimate connectivity from functional magnetic resonance imaging and electrophysiology data, employ Persistent Homology and quantify its ability to distinguish healthy from diseased brain states by applying a support vector machine to features quantifying persistent homology structure. We show how this novel approach compares to classification using standard undirected approaches and original connectivity matrices. In the schizophrenia classification, topological data analysis generally performs close to random, while classifications from raw connectivity perform substantially better; potentially due to topographical, rather than topological, specificity of the differences. In the easier task of seizure discrimination from scalp electroencephalography data, classification based on persistent homology features generally reached comparable performance to using raw connectivity, albeit with typically smaller accuracies obtained for the directed (effective) connectivity compared to the undirected (functional) connectivity. Specific applications for topological data analysis may open when direct comparison of connectivity matrices is unsuitable - such as for intracranial electrophysiology with individual number and location of measurements. While standard homology performed overall better than directed homology, this could be due to notorious technical problems of accurate effective connectivity estimation.}
}
@article{CIPRIANI2023107655,
title = {Topology-based goodness-of-fit tests for sliced spatial data},
journal = {Computational Statistics & Data Analysis},
volume = {179},
pages = {107655},
year = {2023},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2022.107655},
url = {https://www.sciencedirect.com/science/article/pii/S0167947322002353},
author = {Alessandra Cipriani and Christian Hirsch and Martina Vittorietti},
keywords = {Topological data analysis, Persistence diagram, Materials science, Vineyards, Goodness-of-fit tests, Asymptotic normality},
abstract = {In materials science and many other application domains, 3D information can often only be obtained by extrapolating from 2D slices. In topological data analysis, persistence vineyards have emerged as a powerful tool to take into account topological features stretching over several slices. It is illustrated how persistence vineyards can be used to design rigorous statistical hypothesis tests for 3D microstructure models based on data from 2D slices. More precisely, by establishing the asymptotic normality of suitable longitudinal and cross-sectional summary statistics, goodness-of-fit tests that become asymptotically exact in large sampling windows are devised. The testing methodology is illustrated through a detailed simulation study and a prototypical example from materials science is provided.}
}
@article{AHMEDTARISTIZABAL2022102027,
title = {A survey on graph-based deep learning for computational histopathology},
journal = {Computerized Medical Imaging and Graphics},
volume = {95},
pages = {102027},
year = {2022},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2021.102027},
url = {https://www.sciencedirect.com/science/article/pii/S0895611121001762},
author = {David Ahmedt-Aristizabal and Mohammad Ali Armin and Simon Denman and Clinton Fookes and Lars Petersson},
keywords = {Digital pathology, Cancer classification, Cell-graph, Tissue-graph, Hierarchical graph representation, Graph Convolutional Networks, Deep learning},
abstract = {With the remarkable success of representation learning for prediction problems, we have witnessed a rapid expansion of the use of machine learning and deep learning for the analysis of digital pathology and biopsy image patches. However, learning over patch-wise features using convolutional neural networks limits the ability of the model to capture global contextual information and comprehensively model tissue composition. The phenotypical and topological distribution of constituent histological entities play a critical role in tissue diagnosis. As such, graph data representations and deep learning have attracted significant attention for encoding tissue representations, and capturing intra- and inter- entity level interactions. In this review, we provide a conceptual grounding for graph analytics in digital pathology, including entity-graph construction and graph architectures, and present their current success for tumor localization and classification, tumor invasion and staging, image retrieval, and survival prediction. We provide an overview of these methods in a systematic manner organized by the graph representation of the input image, scale, and organ on which they operate. We also outline the limitations of existing techniques, and suggest potential future research directions in this domain.}
}
@article{ROACH2024237,
title = {Automated evaluation of hip abductor muscle quality and size in hip osteoarthritis: Localized muscle regions are strongly associated with overall muscle quality},
journal = {Magnetic Resonance Imaging},
volume = {111},
pages = {237-245},
year = {2024},
issn = {0730-725X},
doi = {https://doi.org/10.1016/j.mri.2024.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S0730725X24001383},
author = {Koren E. Roach and Alyssa L. Bird and Valentina Pedoia and Sharmila Majumdar and Richard B. Souza},
keywords = {Hip, Osteoarthritis, Muscle, Deep learning},
abstract = {Limited information exists regarding abductor muscle quality variation across its length and which locations are most representative of overall muscle quality. This is exacerbated by time-intensive processes for manual muscle segmentation, which limits feasibility of large cohort analyses. The purpose of this study was to develop an automated and localized analysis pipeline that accurately estimates hip abductor muscle quality and size in individuals with mild-to-moderate hip osteoarthritis (OA) and identifies regions of each muscle which provide best estimates of overall muscle quality. Forty-four participants (age 52.7 ± 16.1 years, BMI 23.7 ± 3.4 kg/m2, 14 males) with and without mild-to-moderate radiographic hip OA were recruited for this study. Unilateral hip magnetic resonance (MR) images were acquired on a 3.0 T MR scanner and included axial T1-weighted fast spin echo and 3D axial Iterative Decomposition of water and fat with Echo Asymmetry and Least-squares estimation (IDEAL-IQ) spoiled gradient-recalled echo (SPGR) with multi-peak fat spectrum modeling and single T2* correction. A three dimensional (3D) V-Net convolutional neural network was trained to automatically segment the gluteus medius (GMED), gluteus minimus (GMIN), and tensor fascia lata (TFL) on axial IDEAL-IQ. Agreement between manual and automatic segmentation and associations between axial fat fraction (FF) estimated from IDEAL-IQ and overall muscle FF were evaluated. Dice scores for automatic segmentation were 0.94, 0.87, and 0.91 for GMED, GMIN, and TFL, respectively. GMED, GMIN, and TFL volumetric and FF measures were strongly correlated (r: 0.92–0.99) between automatic and manual segmentations, where all values fell within the 95% limits of agreement of [−9.79 cm3, 17.43 cm3] and [−1.99%, 2.89%], respectively. Axial FF was significantly associated with overall FF with the strongest correlations at 50%, 50%, and 65% the length of the GMED, GMIN, and TFL muscles, respectively (r: 0.93–0.97). An automated and localized analysis can provide efficient and accurate estimates of hip abductor muscle quality and size across muscle length. Specific regions of the muscle may be used to estimate overall muscle quality in an abbreviated evaluation of muscle quality.}
}
@article{JOHNSON20182668,
title = {Artificial Intelligence in Cardiology},
journal = {Journal of the American College of Cardiology},
volume = {71},
number = {23},
pages = {2668-2679},
year = {2018},
issn = {0735-1097},
doi = {https://doi.org/10.1016/j.jacc.2018.03.521},
url = {https://www.sciencedirect.com/science/article/pii/S0735109718344085},
author = {Kipp W. Johnson and Jessica {Torres Soto} and Benjamin S. Glicksberg and Khader Shameer and Riccardo Miotto and Mohsin Ali and Euan Ashley and Joel T. Dudley},
keywords = {artificial intelligence, cardiology, machine learning, precision medicine},
abstract = {Artificial intelligence and machine learning are poised to influence nearly every aspect of the human condition, and cardiology is not an exception to this trend. This paper provides a guide for clinicians on relevant aspects of artificial intelligence and machine learning, reviews selected applications of these methods in cardiology to date, and identifies how cardiovascular medicine could incorporate artificial intelligence in the future. In particular, the paper first reviews predictive modeling concepts relevant to cardiology such as feature selection and frequent pitfalls such as improper dichotomization. Second, it discusses common algorithms used in supervised learning and reviews selected applications in cardiology and related disciplines. Third, it describes the advent of deep learning and related methods collectively called unsupervised learning, provides contextual examples both in general medicine and in cardiovascular medicine, and then explains how these methods could be applied to enable precision cardiology and improve patient outcomes.}
}
@article{JIAO2024107840,
title = {Learning with limited annotations: A survey on deep semi-supervised learning for medical image segmentation},
journal = {Computers in Biology and Medicine},
volume = {169},
pages = {107840},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107840},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523013057},
author = {Rushi Jiao and Yichi Zhang and Le Ding and Bingsen Xue and Jicong Zhang and Rong Cai and Cheng Jin},
keywords = {Medical image segmentation, Semi-supervised learning, Convolutional neural network, Survey},
abstract = {Medical image segmentation is a fundamental and critical step in many image-guided clinical approaches. Recent success of deep learning-based segmentation methods usually relies on a large amount of labeled data, which is particularly difficult and costly to obtain, especially in the medical imaging domain where only experts can provide reliable and accurate annotations. Semi-supervised learning has emerged as an appealing strategy and been widely applied to medical image segmentation tasks to train deep models with limited annotations. In this paper, we present a comprehensive review of recently proposed semi-supervised learning methods for medical image segmentation and summarize both the technical novelties and empirical results. Furthermore, we analyze and discuss the limitations and several unsolved problems of existing approaches. We hope this review can inspire the research community to explore solutions to this challenge and further advance the field of medical image segmentation.}
}
@incollection{DSOUZA2023173,
title = {Chapter 8 - Network comparisons and their applications in connectomics},
editor = {Markus D Schirmer and Tomoki Arichi and Ai Wern Chung},
booktitle = {Connectome Analysis},
publisher = {Academic Press},
pages = {173-199},
year = {2023},
isbn = {978-0-323-85280-7},
doi = {https://doi.org/10.1016/B978-0-323-85280-7.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323852807000099},
author = {Niharika S. D’Souza and Archana Venkataraman},
keywords = {Graph theory, mechanistic network models, network decompositions, machine learning, deep learning, geometric techniques, dynamic networks},
abstract = {Over the past decade, there has been a growing emphasis on neuroscience to analyze the human brain from the perspective of complex networks. Here, connectomics, or the study of underlying connectivity patterns in the brain, has provided several fundamental insights into its intrinsic organization. However, hypothesis-driven discovery in this domain is extremely challenging due to the high data dimensionality, environmental confounds, and considerable interindividual variability. In light of these challenges, this chapter provides a deep dive into network-based analyses in connectomics. Specifically, we will introduce the idea of “network comparison” from two complementary perspectives: capturing group differences using simple graph-theoretic measures and mechanistic network models that integrate another layer of complexity to parse connectomics data. Next, we examine data-driven approaches to network comparison that can capture intersubject variability. These approaches span classical machine learning, geometric techniques, and deep learning. We conclude with a brief snapshot on extending network comparison concepts to dynamic network analysis, as a prelude to later chapters of this book.}
}