{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237efcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Todo está listo para web scraping!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "print(\"¡Todo está listo para web scraping!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a3d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definiendo la consulta \n",
    "query = '(\"Topological data analysis\" OR \"landscape persistence diagrams\") AND (\"Neuroimage\" OR \"Magnetic Resonance Image\") AND (\"confidence interval\" OR \"Estimation\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082fbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libreria \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792e5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://scholar.google.com/scholar?q=(\"Topological+data+analysis\"+OR+\"landscape+persistence+diagrams\")+AND+(\"Neuroimage\"+OR+\"Magnetic+Resonance+Image\")+AND+(\"confidence+interval\"+OR+\"Estimation\")&start=0\n",
      "Error al acceder a la página: 429\n",
      "Resultados guardados en google_scholar_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Función para construir la URL de búsqueda\n",
    "def build_google_scholar_url(query, start=0):\n",
    "    base_url = \"https://scholar.google.com/scholar\"\n",
    "    return f\"{base_url}?q={query.replace(' ', '+')}&start={start}\"\n",
    "\n",
    "# Función para hacer scraping de una página de resultados\n",
    "def scrape_google_scholar(query, max_results=20):\n",
    "    all_results = []\n",
    "    start = 0\n",
    "\n",
    "    while len(all_results) < max_results:\n",
    "        url = build_google_scholar_url(query, start)\n",
    "        print(f\"Scraping: {url}\")\n",
    "        \n",
    "        # Hacer la solicitud\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al acceder a la página: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        # Analizar el HTML\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        articles = soup.find_all(\"div\", class_=\"gs_r gs_or gs_scl\")\n",
    "        \n",
    "        for article in articles:\n",
    "            title = article.find(\"h3\", class_=\"gs_rt\")\n",
    "            title_text = title.text if title else \"Sin título\"\n",
    "            link = title.a['href'] if title and title.a else \"Sin enlace\"\n",
    "            snippet = article.find(\"div\", class_=\"gs_rs\")\n",
    "            snippet_text = snippet.text if snippet else \"Sin resumen\"\n",
    "            year = \"No especificado\"\n",
    "            try:\n",
    "                year = article.find(\"div\", class_=\"gs_a\").text.split()[-1]\n",
    "                if not year.isdigit():\n",
    "                    year = \"No especificado\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            all_results.append({\"Título\": title_text, \"Resumen\": snippet_text, \"Año\": year, \"URL\": link})\n",
    "            \n",
    "            if len(all_results) >= max_results:\n",
    "                break\n",
    "\n",
    "        # Avanzar a la siguiente página\n",
    "        start += 10\n",
    "        time.sleep(2)  # Pausa para evitar bloqueos\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Parámetros de búsqueda\n",
    "query = '(\"Topological data analysis\" OR \"landscape persistence diagrams\") AND (\"Neuroimage\" OR \"Magnetic Resonance Image\") AND (\"confidence interval\" OR \"Estimation\")'\n",
    "max_results = 20\n",
    "\n",
    "# Hacer scraping\n",
    "results = scrape_google_scholar(query, max_results)\n",
    "\n",
    "# Guardar resultados en un archivo CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"google_scholar_results.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Resultados guardados en google_scholar_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803ee40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://scholar.google.com/scholar?q=(\"Topological+data+analysis\"+OR+\"landscape+persistence+diagrams\")+AND+(\"Neuroimage\"+OR+\"Magnetic+Resonance+Image\")+AND+(\"confidence+interval\"+OR+\"Estimation\")&start=0\n",
      "Error al acceder a la página: 429\n",
      "Scraping: https://scholar.google.com/scholar?q=(\"Topological+data+analysis\"+OR+\"landscape+persistence+diagrams\")+AND+(\"Neuroimage\"+OR+\"Magnetic+Resonance+Image\")+AND+(\"confidence+interval\"+OR+\"Estimation\")&start=10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError al procesar la solicitud: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pausa entre solicitudes para evitar bloqueos\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Guardar los resultados en un archivo CSV\u001b[39;00m\n\u001b[1;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Función para construir la URL de búsqueda\n",
    "def build_google_scholar_url(query, start=0):\n",
    "    base_url = \"https://scholar.google.com/scholar\"\n",
    "    return f\"{base_url}?q={query.replace(' ', '+')}&start={start}\"\n",
    "\n",
    "# Encabezados HTTP para simular un navegador\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "# Consulta de búsqueda\n",
    "query = '(\"Topological data analysis\" OR \"landscape persistence diagrams\") AND (\"Neuroimage\" OR \"Magnetic Resonance Image\") AND (\"confidence interval\" OR \"Estimation\")'\n",
    "\n",
    "# Inicializar lista para almacenar resultados\n",
    "results = []\n",
    "\n",
    "# Realizar scraping en múltiples páginas de resultados (ajustar el rango si necesitas más resultados)\n",
    "for start in range(0, 50, 10):  # Cambia 50 por la cantidad deseada de resultados (10 resultados por página)\n",
    "    url = build_google_scholar_url(query, start=start)\n",
    "    print(f\"Scraping: {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            \n",
    "            # Extraer resultados individuales\n",
    "            for entry in soup.select(\".gs_r\"):  # Selector para cada entrada de resultado\n",
    "                title = entry.select_one(\".gs_rt\")\n",
    "                if title and title.a:  # Verifica que haya un enlace\n",
    "                    title_text = title.a.text.strip()\n",
    "                    link = title.a[\"href\"]\n",
    "                else:\n",
    "                    title_text = \"No title available\"\n",
    "                    link = None\n",
    "                \n",
    "                # Opcional: extraer más datos como autores o fragmentos\n",
    "                snippet = entry.select_one(\".gs_rs\")\n",
    "                snippet_text = snippet.text.strip() if snippet else \"No snippet available\"\n",
    "                \n",
    "                results.append({\"Title\": title_text, \"Link\": link, \"Snippet\": snippet_text})\n",
    "        else:\n",
    "            print(f\"Error al acceder a la página: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la solicitud: {e}\")\n",
    "    \n",
    "    time.sleep(15)  # Pausa entre solicitudes para evitar bloqueos\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"google_scholar_results.csv\", index=False)\n",
    "print(\"Resultados guardados en google_scholar_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-scholarly",
   "language": "python",
   "name": "scholarly_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
